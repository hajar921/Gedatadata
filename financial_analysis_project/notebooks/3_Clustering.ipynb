{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Analysis\n",
    "\n",
    "This notebook implements K-Means clustering with PCA to segment financial data into meaningful groups. We'll identify natural patterns in the data and characterize different performance profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from ml_utils import plot_elbow_method, plot_pca_components, plot_clusters\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories for saving results if they don't exist\n",
    "Path('../results/models').mkdir(parents=True, exist_ok=True)\n",
    "Path('../results/plots/ml').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "cleaned_data_path = '../data/processed/cleaned_data.csv'\n",
    "df = pd.read_csv(cleaned_data_path)\n",
    "\n",
    "# Strip spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Replace spaces in column names with underscores (if needed)\n",
    "column_mapping = {col: col.replace(' ', '_') for col in df.columns if ' ' in col}\n",
    "if column_mapping:\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    print(\"Columns renamed to replace spaces with underscores:\")\n",
    "    for old, new in column_mapping.items():\n",
    "        print(f\"  '{old}' â†’ '{new}'\")\n",
    "\n",
    "# Define financial columns for cleaning\n",
    "financial_cols = ['Sales', 'COGS', 'Profit']\n",
    "\n",
    "# Ensure all financial columns exist in the dataset\n",
    "missing_financial_cols = [col for col in financial_cols if col not in df.columns]\n",
    "if missing_financial_cols:\n",
    "    raise ValueError(f\"Missing required financial columns: {missing_financial_cols}\")\n",
    "\n",
    "# Clean financial columns by removing non-numeric characters and handling NaNs\n",
    "for col in financial_cols:\n",
    "    # Remove $, commas, and other non-numeric characters\n",
    "    df[col] = df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True)\n",
    "    \n",
    "    # Replace empty strings with NaN\n",
    "    df[col] = df[col].replace('', np.nan)\n",
    "    \n",
    "    # Convert to numeric, coercing invalid entries to NaN\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in financial columns (or fill as needed)\n",
    "df = df.dropna(subset=financial_cols)\n",
    "\n",
    "# Verify data types after cleaning\n",
    "print(\"\\nData Types After Cleaning:\")\n",
    "print(df[financial_cols].dtypes)\n",
    "\n",
    "# Print cleaned financial columns for verification\n",
    "print(\"\\nCleaned Financial Columns (First 5 Rows):\")\n",
    "print(df[financial_cols].head())\n",
    "\n",
    "# Display basic information about the cleaned dataset\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(\"\\nFull Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Recalculate derived metrics (e.g., ROA and Profit Margin) if needed\n",
    "df['ROA'] = df['Profit'] / df['COGS']\n",
    "df['Profit_Margin'] = df['Profit'] / df['Sales']\n",
    "\n",
    "# Handle potential division by zero or infinity\n",
    "df['ROA'] = df['ROA'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "df['Profit_Margin'] = df['Profit_Margin'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Display summary statistics for key metrics\n",
    "print(\"\\nSummary Statistics for Key Metrics:\")\n",
    "print(df[['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin']].describe())\n",
    "\n",
    "# Save the cleaned and processed data for further use\n",
    "processed_data_path = '../data/processed/ready_for_analysis.csv'\n",
    "df.to_csv(processed_data_path, index=False)\n",
    "print(f\"\\nProcessed data saved to: {processed_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate ROA and Profit_Margin\n",
    "df['Profit_Margin'] = df['Profit'] / df['Sales']\n",
    "df['Profit_Margin'] = df['Profit_Margin'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "df['ROA'] = df['Profit'] / df['COGS']\n",
    "df['ROA'] = df['ROA'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"Columns after adding ROA and Profit_Margin:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "# Numeric features\n",
    "numeric_features = ['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin']\n",
    "\n",
    "# Categorical feature\n",
    "categorical_features = ['Segment']\n",
    "\n",
    "# Check if all selected features exist in the dataframe\n",
    "for feature in numeric_features + categorical_features:\n",
    "    if feature not in df.columns:\n",
    "        print(f\"Warning: {feature} not found in the dataframe.\")\n",
    "\n",
    "# Create a copy of the data with selected features\n",
    "clustering_data = df[numeric_features + categorical_features].copy()\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Clustering Data:\")\n",
    "print(clustering_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Segment'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = preprocessor.fit_transform(clustering_data)\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = ohe.get_feature_names_out(['Segment'])  # Adjust if more categorical features are added\n",
    "feature_names = ['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin'] + list(cat_feature_names)\n",
    "\n",
    "# Display preprocessing results\n",
    "print(f\"Shape after preprocessing: {X_preprocessed.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply PCA for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Apply PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "print(f\"Shape after PCA: {X_pca.shape}\")\n",
    "print(f\"Number of components: {pca.n_components_}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "# Visualize explained variance by components\n",
    "plot_pca_components(pca, '../results/plots/ml/pca_explained_variance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Determine Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = min(15, X_pca.shape[0])  # Ensure max_clusters <= n_samples\n",
    "output_path = '../results/plots/ml/kmeans_elbow_method.png'\n",
    "\n",
    "plot_elbow_method(X_pca, max_clusters=max_clusters, random_state=42, output_path=output_path)\n",
    "# Set the optimal number of clusters to 2 (based on prior analysis)\n",
    "optimal_k = 2\n",
    "\n",
    "print(f\"Optimal number of clusters (default): {optimal_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means clustering with the default number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Display the count of data points in each cluster\n",
    "print(\"Cluster distribution:\")\n",
    "print(df['Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in 2D space (using first two PCA components)\n",
    "plot_clusters(X_pca, cluster_labels, '../results/plots/ml/kmeans_clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_analysis = df.groupby('Cluster').agg({\n",
    "    'Sales': 'mean',\n",
    "    'COGS': 'mean',\n",
    "    'Profit': 'mean',\n",
    "    'ROA': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Cluster': 'count'\n",
    "}).rename(columns={'Cluster': 'Count'}).sort_values('Profit', ascending=False)\n",
    "\n",
    "print(\"Cluster characteristics:\")\n",
    "cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster characteristics\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot metrics by cluster\n",
    "metrics = ['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin']\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.barplot(x='Cluster', y=metric, data=df)\n",
    "    plt.title(f'Average {metric} by Cluster')\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/cluster_characteristics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze segment distribution across clusters\n",
    "segment_cluster = pd.crosstab(df['Segment'], df['Cluster'], normalize='index') * 100\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "segment_cluster.plot(kind='bar', stacked=True)\n",
    "plt.title('Segment Distribution Across Clusters')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/segment_cluster_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Assign Meaningful Cluster Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign meaningful labels to clusters based on their characteristics\n",
    "def assign_cluster_labels(cluster_analysis):\n",
    "    # Sort clusters by profit (high to low)\n",
    "    profit_order = cluster_analysis.sort_values('Profit', ascending=False).index.tolist()\n",
    "    \n",
    "    # Sort clusters by ROA (high to low)\n",
    "    roa_order = cluster_analysis.sort_values('ROA', ascending=False).index.tolist()\n",
    "    \n",
    "    # Sort clusters by profit margin (high to low)\n",
    "    margin_order = cluster_analysis.sort_values('Profit_Margin', ascending=False).index.tolist()\n",
    "    \n",
    "    # Create labels dictionary\n",
    "    cluster_labels = {}\n",
    "    \n",
    "    for cluster in cluster_analysis.index:\n",
    "        # Determine profit level\n",
    "        profit_rank = profit_order.index(cluster)\n",
    "        profit_level = \"High Profit\" if profit_rank < len(profit_order) / 3 else \\\n",
    "                      \"Medium Profit\" if profit_rank < 2 * len(profit_order) / 3 else \"Low Profit\"\n",
    "        \n",
    "        # Determine ROA level\n",
    "        roa_rank = roa_order.index(cluster)\n",
    "        roa_level = \"High ROA\" if roa_rank < len(roa_order) / 3 else \\\n",
    "                   \"Medium ROA\" if roa_rank < 2 * len(roa_order) / 3 else \"Low ROA\"\n",
    "        \n",
    "        # Combine labels\n",
    "        cluster_labels[cluster] = f\"{profit_level}/{roa_level}\"\n",
    "    \n",
    "    return cluster_labels\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels_dict = assign_cluster_labels(cluster_analysis)\n",
    "print(\"Cluster labels:\")\n",
    "for cluster, label in cluster_labels_dict.items():\n",
    "    print(f\"Cluster {cluster}: {label}\")\n",
    "\n",
    "# Add descriptive labels to the dataframe\n",
    "df['Cluster_Label'] = df['Cluster'].map(cluster_labels_dict)\n",
    "\n",
    "# Display the count of data points in each labeled cluster\n",
    "print(\"\\nLabeled cluster distribution:\")\n",
    "print(df['Cluster_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustering model and preprocessor\n",
    "clustering_model = {\n",
    "    'preprocessor': preprocessor,\n",
    "    'pca': pca,\n",
    "    'kmeans': kmeans,\n",
    "    'cluster_labels': cluster_labels_dict\n",
    "}\n",
    "\n",
    "with open('../results/models/clustering_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clustering_model, f)\n",
    "\n",
    "print(\"Clustering model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cluster Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize cluster characteristics with labels\n",
    "labeled_cluster_analysis = df.groupby('Cluster_Label').agg({\n",
    "    'Sales': 'mean',\n",
    "    'COGS': 'mean',\n",
    "    'Profit': 'mean',\n",
    "    'ROA': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Cluster_Label': 'count'\n",
    "}).rename(columns={'Cluster_Label': 'Count'}).sort_values('Profit', ascending=False)\n",
    "\n",
    "print(\"Labeled cluster characteristics:\")\n",
    "labeled_cluster_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Insights:\n",
    "\n",
    "Based on the clustering analysis, we identified distinct financial performance clusters, each with unique characteristics. Key insights include:\n",
    "\n",
    "- **Cluster Characteristics**:\n",
    "  - **High Profit / High ROA Cluster**: Represents top-performing segments with exceptional profitability and return on assets.\n",
    "  - **Low Profit / Low ROA Cluster**: Indicates areas that require immediate attention and strategic intervention.\n",
    "\n",
    "- **Segment-Specific Performance**:\n",
    "  - Certain segments show a strong presence in high-performing clusters, suggesting industry-specific advantages.\n",
    "\n",
    "#### Recommendations Based on Clustering:\n",
    "1. **Strategic Focus on High-Potential Segments**:\n",
    "   - Allocate more resources to segments that appear frequently in the \"High Profit / High ROA\" cluster.\n",
    "\n",
    "2. **Targeted Interventions for Underperforming Units**:\n",
    "   - Develop specific strategies for entities in the \"Low Profit / Low ROA\" cluster, focusing on improving key metrics.\n",
    "\n",
    "3. **Performance Benchmarking**:\n",
    "   - Establish cluster-based benchmarks for different business units, recognizing that different segments may have different performance profiles.\n",
    "\n",
    "4. **Segment-Specific Strategies**:\n",
    "   - Develop tailored approaches for each segment based on their cluster distribution patterns.\n",
    "\n",
    "5. **Cross-Segment Learning**:\n",
    "   - Identify best practices from segments that consistently appear in high-performing clusters and apply them to underperforming segments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe with cluster labels for use in other notebooks\n",
    "df.to_csv('../data/processed/clustered_data.csv', index=False)\n",
    "\n",
    "# Save cluster analysis summary\n",
    "labeled_cluster_analysis.to_csv('../results/reports/cluster_analysis_summary.csv')\n",
    "\n",
    "print(\"Results saved for further analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
