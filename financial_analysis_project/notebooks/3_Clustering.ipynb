{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Clustering Analysis\n",
       "\n",
       "This notebook implements K-Means clustering with PCA to segment financial data into meaningful groups. We'll identify natural patterns in the data and characterize different performance profiles."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Import necessary libraries\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from pathlib import Path\n",
       "import warnings\n",
       "import pickle\n",
       "\n",
       "# Machine learning libraries\n",
       "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn.decomposition import PCA\n",
       "from sklearn.cluster import KMeans\n",
       "\n",
       "# Import custom modules\n",
       "import sys\n",
       "import os\n",
       "sys.path.append(os.path.abspath('../src'))\n",
       "from ml_utils import plot_elbow_method, plot_pca_components, plot_clusters\n",
       "\n",
       "# Set plotting style\n",
       "sns.set(style='whitegrid')\n",
       "plt.style.use('seaborn-whitegrid')\n",
       "\n",
       "# Ignore warnings\n",
       "warnings.filterwarnings('ignore')\n",
       "\n",
       "# Create directories for saving results if they don't exist\n",
       "Path('../results/models').mkdir(parents=True, exist_ok=True)\n",
       "Path('../results/plots/ml').mkdir(parents=True, exist_ok=True)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Load and Prepare Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Load the cleaned data\n",
       "df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
       "\n",
       "# Display basic information\n",
       "print(f\"Dataset shape: {df.shape}\")\n",
       "df.head()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Feature Selection for Clustering"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Select features for clustering\n",
       "# Numeric features for clustering\n",
       "numeric_features = ['Revenue', 'Cost', 'Profit', 'ROA', 'Profit_Margin']\n",
       "\n",
       "# Categorical features to encode\n",
       "categorical_features = ['Segment', 'Country']\n",
       "\n",
       "# Check if all selected features exist in the dataframe\n",
       "for feature in numeric_features + categorical_features:\n",
       "    if feature not in df.columns:\n",
       "        print(f\"Warning: {feature} not found in the dataframe.\")\n",
       "\n",
       "# Create a copy of the data with selected features\n",
       "clustering_data = df[numeric_features + categorical_features].copy()\n",
       "\n",
       "# Display the first few rows\n",
       "clustering_data.head()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Preprocessing for Clustering"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Define preprocessing steps\n",
       "# For numeric features: scaling\n",
       "# For categorical features: one-hot encoding\n",
       "\n",
       "# Create preprocessor\n",
       "preprocessor = ColumnTransformer(\n",
       "    transformers=[\n",
       "        ('num', StandardScaler(), numeric_features),\n",
       "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
       "    ])\n",
       "\n",
       "# Apply preprocessing\n",
       "X_preprocessed = preprocessor.fit_transform(clustering_data)\n",
       "\n",
       "# Get feature names after one-hot encoding\n",
       "ohe = preprocessor.named_transformers_['cat']\n",
       "cat_feature_names = ohe.get_feature_names_out(categorical_features)\n",
       "feature_names = numeric_features + list(cat_feature_names)\n",
       "\n",
       "print(f\"Shape after preprocessing: {X_preprocessed.shape}\")\n",
       "print(f\"Number of features: {len(feature_names)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Apply PCA for Dimensionality Reduction"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Apply PCA to reduce dimensionality while retaining 95% of variance\n",
       "pca = PCA(n_components=0.95)\n",
       "X_pca = pca.fit_transform(X_preprocessed)\n",
       "\n",
       "print(f\"Shape after PCA: {X_pca.shape}\")\n",
       "print(f\"Number of components: {pca.n_components_}\")\n",
       "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
       "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2f}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Visualize explained variance by components\n",
       "plot_pca_components(pca, '../results/plots/ml/pca_explained_variance.png')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Determine Optimal Number of Clusters"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Use the elbow method to find the optimal number of clusters\n",
       "k_range = range(2, 15)\n",
       "optimal_k = plot_elbow_method(X_pca, k_range, '../results/plots/ml/kmeans_elbow_method.png')\n",
       "\n",
       "print(f\"Optimal number of clusters based on elbow method: {optimal_k}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Apply K-Means Clustering"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Apply K-Means clustering with the optimal number of clusters\n",
       "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
       "cluster_labels = kmeans.fit_predict(X_pca)\n",
       "\n",
       "# Add cluster labels to the original dataframe\n",
       "df['Cluster'] = cluster_labels\n",
       "\n",
       "# Display the count of data points in each cluster\n",
       "print(\"Cluster distribution:\")\n",
       "print(df['Cluster'].value_counts())"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Visualize clusters in 2D space (using first two PCA components)\n",
       "plot_clusters(X_pca, cluster_labels, '../results/plots/ml/kmeans_clusters.png')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Analyze Cluster Characteristics"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Analyze cluster characteristics\n",
       "cluster_analysis = df.groupby('Cluster').agg({\n",
       "    'Revenue': 'mean',\n",
       "    'Cost': 'mean',\n",
       "    'Profit': 'mean',\n",
       "    'ROA': 'mean',\n",
       "    'Profit_Margin': 'mean',\n",
       "    'Cluster': 'count'\n",
       "}).rename(columns={'Cluster': 'Count'}).sort_values('Profit', ascending=False)\n",
       "\n",
       "print(\"Cluster characteristics:\")\n",
       "cluster_analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Visualize cluster characteristics\n",
       "plt.figure(figsize=(14, 10))\n",
       "\n",
       "# Plot metrics by cluster\n",
       "metrics = ['Revenue', 'Cost', 'Profit', 'ROA', 'Profit_Margin']\n",
       "for i, metric in enumerate(metrics):\n",
       "    plt.subplot(2, 3, i+1)\n",
       "    sns.barplot(x='Cluster', y=metric, data=df)\n",
       "    plt.title(f'Average {metric} by Cluster')\n",
       "    plt.grid(axis='y')\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.savefig('../results/plots/ml/cluster_characteristics.png')\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Analyze segment distribution across clusters\n",
       "segment_cluster = pd.crosstab(df['Segment'], df['Cluster'], normalize='index') * 100\n",
       "\n",
       "plt.figure(figsize=(14, 8))\n",
       "segment_cluster.plot(kind='bar', stacked=True)\n",
       "plt.title('Segment Distribution Across Clusters')\n",
       "plt.xlabel('Segment')\n",
       "plt.ylabel('Percentage (%)')\n",
       "plt.legend(title='Cluster')\n",
       "plt.grid(axis='y')\n",
       "plt.tight_layout()\n",
       "plt.savefig('../results/plots/ml/segment_cluster_distribution.png')\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Assign Meaningful Cluster Labels"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Assign meaningful labels to clusters based on their characteristics\n",
       "def assign_cluster_labels(cluster_analysis):\n",
       "    # Sort clusters by profit (high to low)\n",
       "    profit_order = cluster_analysis.sort_values('Profit', ascending=False).index.tolist()\n",
       "    \n",
       "    # Sort clusters by ROA (high to low)\n",
       "    roa_order = cluster_analysis.sort_values('ROA', ascending=False).index.tolist()\n",
       "    \n",
       "    # Sort clusters by profit margin (high to low)\n",
       "    margin_order = cluster_analysis.sort_values('Profit_Margin', ascending=False).index.tolist()\n",
       "    \n",
       "    # Create labels dictionary\n",
       "    cluster_labels = {}\n",
       "    \n",
       "    for cluster in cluster_analysis.index:\n",
       "        # Determine profit level\n",
       "        profit_rank = profit_order.index(cluster)\n",
       "        profit_level = \"High Profit\" if profit_rank < len(profit_order) / 3 else \\\n",
       "                      \"Medium Profit\" if profit_rank < 2 * len(profit_order) / 3 else \"Low Profit\"\n",
       "        \n",
       "        # Determine ROA level\n",
       "        roa_rank = roa_order.index(cluster)\n",
       "        roa_level = \"High ROA\" if roa_rank < len(roa_order) / 3 else \\\n",
       "                   \"Medium ROA\" if roa_rank < 2 * len(roa_order) / 3 else \"Low ROA\"\n",
       "        \n",
       "        # Combine labels\n",
       "        cluster_labels[cluster] = f\"{profit_level}/{roa_level}\"\n",
       "    \n",
       "    return cluster_labels\n",
       "\n",
       "# Get cluster labels\n",
       "cluster_labels_dict = assign_cluster_labels(cluster_analysis)\n",
       "print(\"Cluster labels:\")\n",
       "for cluster, label in cluster_labels_dict.items():\n",
       "    print(f\"Cluster {cluster}: {label}\")\n",
       "\n",
       "# Add descriptive labels to the dataframe\n",
       "df['Cluster_Label'] = df['Cluster'].map(cluster_labels_dict)\n",
       "\n",
       "# Display the count of data points in each labeled cluster\n",
       "print(\"\\nLabeled cluster distribution:\")\n",
       "print(df['Cluster_Label'].value_counts())"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
         "# Save the clustering model and preprocessor\n",
         "clustering_model = {\n",
         "    'preprocessor': preprocessor,\n",
         "    'pca': pca,\n",
         "    'kmeans': kmeans,\n",
         "    'cluster_labels': cluster_labels_dict\n",
         "}\n",
         "\n",
         "with open('../results/models/clustering_model.pkl', 'wb') as f:\n",
         "    pickle.dump(clustering_model, f)\n",
         "\n",
         "print(\"Clustering model saved.\")"
        ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## 9. Cluster Insights and Recommendations"
    ]
    },
    {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
    "# Summarize cluster characteristics with labels\n",
    "labeled_cluster_analysis = df.groupby('Cluster_Label').agg({\n",
    "    'Revenue': 'mean',\n",
    "    'Cost': 'mean',\n",
    "    'Profit': 'mean',\n",
    "    'ROA': 'mean',\n",
    "    'Profit_Margin': 'mean',\n",
    "    'Cluster_Label': 'count'\n",
    "}).rename(columns={'Cluster_Label': 'Count'}).sort_values('Profit', ascending=False)\n",
    "\n",
    "print(\"Labeled cluster characteristics:\")\n",
    "labeled_cluster_analysis"
    ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### Clustering Insights:\n",
    "\n",
    "1. We identified {optimal_k} distinct financial performance clusters, each with unique characteristics.\n",
    "2. The \"High Profit/High ROA\" cluster represents our top-performing segment with exceptional profitability and return on assets.\n",
    "3. The \"Low Profit/Low ROA\" cluster indicates areas that need immediate attention and strategic intervention.\n",
    "4. Certain segments show a strong presence in high-performing clusters, suggesting industry-specific advantages.\n",
    "5. The clustering analysis reveals natural groupings that go beyond simple profitability metrics, providing a multi-dimensional view of financial performance.\n",
    "\n",
    "### Recommendations based on Clustering:\n",
    "\n",
    "1. **Strategic Focus on High-Potential Segments**: Allocate more resources to segments that appear frequently in the \"High Profit/High ROA\" cluster.\n",
    "2. **Targeted Interventions for Underperforming Units**: Develop specific strategies for entities in the \"Low Profit/Low ROA\" cluster, focusing on improving the key metrics identified in our analysis.\n",
    "3. **Performance Benchmarking**: Establish cluster-based benchmarks for different business units, recognizing that different segments may have different performance profiles.\n",
    "4. **Segment-Specific Strategies**: Develop tailored approaches for each segment based on their cluster distribution patterns.\n",
    "5. **Cross-Segment Learning**: Identify best practices from segments that consistently appear in high-performing clusters and apply them to underperforming segments where applicable."
    ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## 10. Save Results for Further Analysis"
    ]
    },
    {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "source": [
    "# Save the dataframe with cluster labels for use in other notebooks\n",
    "df.to_csv('../data/processed/clustered_data.csv', index=False)\n",
    "\n",
    "# Save cluster analysis summary\n",
    "labeled_cluster_analysis.to_csv('../results/reports/cluster_analysis_summary.csv')\n",
    "\n",
    "print(\"Results saved for further analysis.\")"
    ]
    }
    ],
    "metadata": {
    "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
    },
    "language_info": {
    "codemirror_mode": {
    "name": "ipython",
    "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.10"
    }
    },
    "nbformat": 4,
    "nbformat_minor": 4
    }