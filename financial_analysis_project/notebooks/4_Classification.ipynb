{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Predict High Net Income\n",
    "\n",
    "This notebook builds a classification model to predict whether a company will have high net income based on various financial and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score ,roc_curve, auc\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from ml_utils import plot_feature_importance, evaluate_classification_model\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories for saving results if they don't exist\n",
    "Path('../results/models').mkdir(parents=True, exist_ok=True)\n",
    "Path('../results/plots/ml').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data with cluster labels if available\n",
    "try:\n",
    "    # Try to load the clustered data first\n",
    "    df = pd.read_csv('../data/processed/clustered_data.csv')\n",
    "    print(\"Loaded data with cluster labels.\")\n",
    "except FileNotFoundError:\n",
    "    # If not available, load the cleaned data\n",
    "    df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "    print(\"Loaded cleaned data without cluster labels.\")\n",
    "\n",
    "# Strip spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Replace spaces in column names with underscores (if needed)\n",
    "column_mapping = {col: col.replace(' ', '_') for col in df.columns if ' ' in col}\n",
    "if column_mapping:\n",
    "    df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Clean financial columns (Sales, COGS, Profit) by removing $, commas, and spaces\n",
    "financial_cols = ['Sales', 'COGS', 'Profit']\n",
    "for col in financial_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True)\n",
    "    df[col] = df[col].replace('', np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in financial columns (or fill as needed)\n",
    "df = df.dropna(subset=financial_cols)\n",
    "\n",
    "# Recalculate derived metrics (e.g., ROA and Profit_Margin)\n",
    "df['ROA'] = df['Profit'] / df['COGS']\n",
    "df['Profit_Margin'] = df['Profit'] / df['Sales']\n",
    "\n",
    "# Handle potential division by zero or infinity\n",
    "df['ROA'] = df['ROA'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "df['Profit_Margin'] = df['Profit_Margin'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target variable: high_net_income (top 20% as \"High\")\n",
    "profit_threshold = df['Profit'].quantile(0.8)\n",
    "df['high_net_income'] = (df['Profit'] >= profit_threshold).astype(int)\n",
    "\n",
    "print(f\"Profit threshold for high net income: {profit_threshold:.2f}\")\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['high_net_income'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target variable distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='high_net_income', data=df)\n",
    "plt.title('Distribution of High Net Income Target Variable')\n",
    "plt.xlabel('High Net Income (1 = Yes, 0 = No)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('../results/plots/ml/high_net_income_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for classification\n",
    "# Numeric features\n",
    "numeric_features_clf = ['Sales', 'COGS', 'Profit', 'ROA', 'Profit_Margin']\n",
    "\n",
    "# Categorical features\n",
    "categorical_features_clf = ['Segment', 'Country']\n",
    "\n",
    "# Add cluster label as a feature if available\n",
    "if 'Cluster' in df.columns:\n",
    "    categorical_features_clf.append('Cluster')\n",
    "\n",
    "# Target variable\n",
    "target = 'high_net_income'\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "X_clf = df[numeric_features_clf + categorical_features_clf]\n",
    "y_clf = df[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Feature Relationships with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationship between numeric features and target\n",
    "plt.figure(figsize=(14, 8))  # Adjust figure size as needed\n",
    "\n",
    "# Determine the number of numeric features\n",
    "num_features = len(numeric_features_clf)\n",
    "\n",
    "# Dynamically calculate grid dimensions\n",
    "num_rows = int(np.ceil(num_features / 2))  # Use 2 columns for simplicity\n",
    "num_cols = 2\n",
    "\n",
    "for i, feature in enumerate(numeric_features_clf):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)  # Dynamically set subplot position\n",
    "    sns.boxplot(x='high_net_income', y=feature, data=df)\n",
    "    plt.title(f'{feature} by High Net Income')\n",
    "    plt.xlabel('High Net Income (1 = Yes, 0 = No)')\n",
    "    plt.ylabel(feature)  # Add a label for clarity\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()  # Ensure subplots do not overlap\n",
    "plt.savefig('../results/plots/ml/numeric_features_by_target.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationship between Segment and target\n",
    "segment_target = pd.crosstab(df['Segment'], df['high_net_income'], normalize='index') * 100\n",
    "segment_target.columns = ['Low Net Income', 'High Net Income']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "segment_target.plot(kind='bar', stacked=True)\n",
    "plt.title('Segment Distribution by High Net Income')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/segment_by_target.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline for classification\n",
    "preprocessor_clf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_clf),  # Scale numeric features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_clf)  # Encode categorical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create classification pipeline with Random Forest and balanced class weights\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_clf),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "\n",
    "# Define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(clf_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "evaluate_classification_model(y_test, y_pred, '../results/plots/ml/classification_confusion_matrix.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "y_proba = best_clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig('../results/plots/ml/classification_roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the random forest classifier from the pipeline\n",
    "rf_clf = best_clf.named_steps['classifier']\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "preprocessor = best_clf.named_steps['preprocessor']\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = ohe.get_feature_names_out(categorical_features_clf)\n",
    "feature_names_clf = numeric_features_clf + list(cat_feature_names)\n",
    "\n",
    "# Plot feature importances\n",
    "feature_importance_df = plot_feature_importance(rf_clf, feature_names_clf, '../results/plots/ml/classification_feature_importance.png')\n",
    "\n",
    "# Display top 10 most important features\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best classification model\n",
    "with open('../results/models/classification_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_clf, f)\n",
    "\n",
    "# Save feature importance data\n",
    "feature_importance_df.to_csv('../results/reports/classification_feature_importance.csv', index=False)\n",
    "\n",
    "print(\"Classification model and feature importance saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Segment-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance by segment\n",
    "# Add predictions to the test data\n",
    "test_data = X_test.copy()\n",
    "test_data['actual'] = y_test.values\n",
    "test_data['predicted'] = y_pred\n",
    "test_data['correct'] = (test_data['actual'] == test_data['predicted']).astype(int)\n",
    "\n",
    "# Calculate accuracy by segment\n",
    "segment_accuracy = test_data.groupby('Segment')['correct'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "segment_accuracy.plot(kind='bar')\n",
    "plt.title('Classification Accuracy by Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axhline(y=test_data['correct'].mean(), color='r', linestyle='--', label=f'Overall Accuracy: {test_data[\"correct\"].mean():.4f}')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/classification_accuracy_by_segment.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Classification Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Insights:\n",
    "The Random Forest classifier achieved near-perfect accuracy in predicting high net income, highlighting its effectiveness in identifying companies likely to achieve high profitability. Key insights include:\n",
    "\n",
    "- **Feature Importance**:\n",
    "  - The most important features for predicting high net income were **Profit**, **Sales**, and **Cluster 0 (\"Medium Profit / High ROA\")**, underscoring their critical role in financial performance.\n",
    "\n",
    "#### Recommendations Based on Classification:\n",
    "1. **Predictive Financial Planning**:\n",
    "   - Implement the classification model in financial planning processes to identify companies likely to achieve high net income.\n",
    "\n",
    "2. **Risk Management**:\n",
    "   - Use the model to identify companies at risk of falling below profit expectations and take preemptive action.\n",
    "\n",
    "3. **Investment Prioritization**:\n",
    "   - Direct investment toward companies that the model predicts have high potential for reaching top-tier profitability.\n",
    "\n",
    "4. **Focus on Key Drivers**:\n",
    "   - Develop strategies that focus on improving the top predictive features identified by the model.\n",
    "\n",
    "5. **Segment-Specific Strategies**:\n",
    "   - Tailor approaches based on segment-specific performance patterns identified in the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
