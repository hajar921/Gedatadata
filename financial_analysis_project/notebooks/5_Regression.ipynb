{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: Predict Profit\n",
    "\n",
    "This notebook builds regression models to predict profit based on various financial and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from ml_utils import plot_feature_importance, evaluate_regression_model, plot_residuals\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories for saving results if they don't exist\n",
    "Path('../results/models').mkdir(parents=True, exist_ok=True)\n",
    "Path('../results/plots/ml').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data with cluster labels if available\n",
    "try:\n",
    "    # Try to load the clustered data first\n",
    "    df = pd.read_csv('../data/processed/clustered_data.csv')\n",
    "    print(\"Loaded data with cluster labels.\")\n",
    "except FileNotFoundError:\n",
    "    # If not available, load the cleaned data\n",
    "    df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "    print(\"Loaded cleaned data without cluster labels.\")\n",
    "\n",
    "# Strip spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Replace spaces in column names with underscores (if needed)\n",
    "column_mapping = {col: col.replace(' ', '_') for col in df.columns if ' ' in col}\n",
    "if column_mapping:\n",
    "    df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Clean financial columns (Sales, COGS, Profit) by removing $, commas, and spaces\n",
    "financial_cols = ['Sales', 'COGS', 'Profit']\n",
    "for col in financial_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True)\n",
    "    df[col] = df[col].replace('', np.nan)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in financial columns (or fill as needed)\n",
    "df = df.dropna(subset=financial_cols)\n",
    "\n",
    "# Recalculate derived metrics (e.g., ROA and Profit_Margin)\n",
    "df['ROA'] = df['Profit'] / df['COGS']\n",
    "df['Profit_Margin'] = df['Profit'] / df['Sales']\n",
    "\n",
    "# Handle potential division by zero or infinity\n",
    "df['ROA'] = df['ROA'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "df['Profit_Margin'] = df['Profit_Margin'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for regression\n",
    "# Numeric features\n",
    "numeric_features_reg = ['Sales', 'COGS', 'ROA', 'Profit_Margin']\n",
    "\n",
    "# Categorical features\n",
    "categorical_features_reg = ['Segment', 'Country']\n",
    "\n",
    "# Add cluster label as a feature if available\n",
    "if 'Cluster' in df.columns:\n",
    "    categorical_features_reg.append('Cluster')\n",
    "\n",
    "# Target variable\n",
    "target = 'Profit'\n",
    "target_reg = 'Profit'\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "X_reg = df[numeric_features_reg + categorical_features_reg]\n",
    "y_reg = df[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_reg.shape}\")\n",
    "print(f\"Testing set shape: {X_test_reg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Feature Relationships with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationship between numeric features and target\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, feature in enumerate(numeric_features_reg):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(df[feature], df[target_reg], alpha=0.5)\n",
    "    plt.title(f'{feature} vs {target_reg}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(target_reg)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/numeric_features_vs_target_reg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with Target\n",
    "\n",
    "Let's check the correlation between numeric features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between numeric features and target\n",
    "corr_with_target = df[numeric_features_reg + [target_reg]].corr()[target_reg].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr_with_target.drop(target_reg).plot(kind='bar')\n",
    "plt.title(f'Correlation with {target_reg}')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/correlation_with_target_reg.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation with target:\")\n",
    "print(corr_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationship between Segment and target\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Segment', y=target_reg, data=df)\n",
    "plt.title(f'Distribution of {target_reg} by Segment')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/profit_by_segment.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline for regression\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_reg),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_reg)\n",
    "    ])\n",
    "\n",
    "# Create regression pipelines with different models\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_reg),\n",
    "    ('regressor', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_reg),\n",
    "    ('regressor', Lasso(random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_reg),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for each model\n",
    "ridge_param_grid = {\n",
    "    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for Ridge regression\n",
    "print(\"Tuning Ridge Regression...\")\n",
    "ridge_grid_search = GridSearchCV(ridge_pipeline, ridge_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_grid_search.fit(X_train_reg, y_train_reg)\n",
    "best_ridge = ridge_grid_search.best_estimator_\n",
    "print(f\"Best Ridge parameters: {ridge_grid_search.best_params_}\")\n",
    "print(f\"Best Ridge RMSE: {np.sqrt(-ridge_grid_search.best_score_):.2f}\")\n",
    "\n",
    "# Perform grid search for Lasso regression\n",
    "print(\"\\nTuning Lasso Regression...\")\n",
    "lasso_grid_search = GridSearchCV(lasso_pipeline, lasso_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lasso_grid_search.fit(X_train_reg, y_train_reg)\n",
    "best_lasso = lasso_grid_search.best_estimator_\n",
    "print(f\"Best Lasso parameters: {lasso_grid_search.best_params_}\")\n",
    "print(f\"Best Lasso RMSE: {np.sqrt(-lasso_grid_search.best_score_):.2f}\")\n",
    "\n",
    "# Perform grid search for Random Forest regression\n",
    "print(\"\\nTuning Random Forest Regression...\")\n",
    "rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train_reg, y_train_reg)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "print(f\"Best Random Forest parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Best Random Forest RMSE: {np.sqrt(-rf_grid_search.best_score_):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set with each model\n",
    "ridge_pred = best_ridge.predict(X_test_reg)\n",
    "lasso_pred = best_lasso.predict(X_test_reg)\n",
    "rf_pred = best_rf.predict(X_test_reg)\n",
    "\n",
    "# Calculate metrics for each model\n",
    "models = ['Ridge', 'Lasso', 'Random Forest']\n",
    "predictions = [ridge_pred, lasso_pred, rf_pred]\n",
    "metrics = []\n",
    "\n",
    "for model_name, y_pred in zip(models, predictions):\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    \n",
    "    metrics.append({\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    })\n",
    "\n",
    "# Create a DataFrame with metrics\n",
    "metrics_df = pd.DataFrame(metrics).set_index('Model')\n",
    "print(\"Model Comparison:\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# RMSE comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=metrics_df.index, y='RMSE', data=metrics_df)\n",
    "plt.title('RMSE by Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# R² comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=metrics_df.index, y='R²', data=metrics_df)\n",
    "plt.title('R² by Model')\n",
    "plt.ylabel('R²')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/regression_model_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on R²\n",
    "best_model_name = metrics_df['R²'].idxmax()\n",
    "best_model = {'Ridge': best_ridge, 'Lasso': best_lasso, 'Random Forest': best_rf}[best_model_name]\n",
    "best_pred = {'Ridge': ridge_pred, 'Lasso': lasso_pred, 'Random Forest': rf_pred}[best_model_name]\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Define the output path for evaluation metrics\n",
    "output_path = '../results/plots/ml/regression_evaluation.png'\n",
    "\n",
    "# Evaluate the best model\n",
    "print(f\"\\nDetailed evaluation of {best_model_name} model:\")\n",
    "model_metrics = evaluate_regression_model(y_test_reg, best_pred, output_path)\n",
    "\n",
    "# Print detailed metrics\n",
    "for metric, value in model_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_reg, best_pred, alpha=0.5)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--')\n",
    "plt.xlabel('Actual Profit')\n",
    "plt.ylabel('Predicted Profit')\n",
    "plt.title(f'{best_model_name}: Actual vs Predicted Profit')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/actual_vs_predicted_profit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plot_residuals(y_test_reg, best_pred, '../results/plots/ml/profit_residuals.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance if the best model is Random Forest\n",
    "if best_model_name == 'Random Forest':\n",
    "    # Extract the random forest regressor from the pipeline\n",
    "    rf_reg = best_model.named_steps['regressor']\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    preprocessor = best_model.named_steps['preprocessor']\n",
    "    ohe = preprocessor.named_transformers_['cat']\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_features_reg)\n",
    "    feature_names_reg = numeric_features_reg + list(cat_feature_names)\n",
    "    \n",
    "    # Plot feature importances\n",
    "    feature_importance_df = plot_feature_importance(rf_reg, feature_names_reg, '../results/plots/ml/regression_feature_importance.png')\n",
    "    \n",
    "    # Display top 10 most important features\n",
    "    print(\"Top 10 most important features:\")\n",
    "    feature_importance_df.head(10)\n",
    "elif best_model_name == 'Ridge' or best_model_name == 'Lasso':\n",
    "    # Extract the regressor from the pipeline\n",
    "    regressor = best_model.named_steps['regressor']\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    preprocessor = best_model.named_steps['preprocessor']\n",
    "    ohe = preprocessor.named_transformers_['cat']\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_features_reg)\n",
    "    feature_names_reg = numeric_features_reg + list(cat_feature_names)\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = regressor.coef_\n",
    "    \n",
    "    # Create a DataFrame for easier sorting\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': feature_names_reg,\n",
    "        'Coefficient': coefficients\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "    \n",
    "# Plot coefficients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coef_df.head(20))\n",
    "    plt.title(f'{best_model_name} Coefficients (Top 20 by Magnitude)')\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/plots/ml/regression_coefficients.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display top 10 coefficients\n",
    "    print(\"Top 10 coefficients by magnitude:\")\n",
    "    print(coef_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best regression model\n",
    "with open('../results/models/regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save model metrics\n",
    "metrics_df.to_csv('../results/reports/regression_model_metrics.csv')\n",
    "\n",
    "print(\"Regression model and metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Segment-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance by segment\n",
    "# Add predictions to the test data\n",
    "test_data_reg = X_test_reg.copy()\n",
    "test_data_reg['actual'] = y_test_reg.values\n",
    "test_data_reg['predicted'] = best_pred\n",
    "test_data_reg['error'] = test_data_reg['actual'] - test_data_reg['predicted']\n",
    "test_data_reg['abs_error'] = abs(test_data_reg['error'])\n",
    "\n",
    "# Calculate MAE by segment\n",
    "segment_mae = test_data_reg.groupby('Segment')['abs_error'].mean().sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "segment_mae.plot(kind='bar')\n",
    "plt.title('Mean Absolute Error by Segment')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('MAE')\n",
    "plt.axhline(y=test_data_reg['abs_error'].mean(), color='r', linestyle='--', label=f'Overall MAE: {test_data_reg[\"abs_error\"].mean():.2f}')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/ml/regression_mae_by_segment.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Regression Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The regression models provided insights into the relationships between financial metrics and target variables (e.g., Profit). Key findings include:\n",
    "\n",
    " *Feature Importance*  :\n",
    "Important predictors of Profit included Sales , COGS , and ROA , reflecting their significant influence on financial outcomes.\n",
    "Model Performance :\n",
    "The models demonstrated strong predictive power, with metrics like R² scores and RMSE indicating good fit and low error.\n",
    "Recommendations Based on Regression :\n",
    " *Financial Forecasting* :\n",
    "Use the regression models to forecast future financial performance based on historical trends and key drivers.\n",
    " *Resource Allocation* :\n",
    "Allocate resources strategically by prioritizing investments in factors that drive profitability, as identified by the regression analysis.\n",
    " *Scenario Analysis* :\n",
    "Conduct scenario analysis to understand how changes in key predictors (e.g., Sales, COGS) impact profitability.\n",
    " *Continuous Monitoring* :\n",
    "Continuously monitor key financial metrics to ensure early detection of deviations from expected performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé des Principaux Résultats ##\n",
    "    **Analyse Exploratoire des Données (EDA)** :\n",
    "Nous avons identifié les principales caractéristiques financières et leurs distributions, révélant des insights sur les performances sectorielles et les corrélations entre variables.\n",
    "    **Clustering** :\n",
    "Le clustering a segmenté les entreprises en groupes distincts selon leur performance financière, mettant en évidence des clusters à haute rentabilité et à faible rentabilité.\n",
    "    **Classification** :\n",
    "Un modèle de classification robuste a été développé pour prédire les revenus élevés, en se basant sur des indicateurs financiers critiques tels que le chiffre d'affaires, les coûts et le ROA (Return on Assets).\n",
    "    **Régression** :\n",
    "Les modèles de régression ont permis de comprendre les relations entre les métriques financières et les variables cibles, fournissant des insights actionnables pour la prévision et l'optimisation.\n",
    "## Recommandations ##\n",
    "    **Prise de Décisions Stratégiques** :\n",
    "Utiliser les insights issus du clustering et de la classification pour informer les décisions stratégiques concernant l'allocation des ressources et la gestion des risques.\n",
    "    **Amélioration Continue**  :\n",
    "Mettre régulièrement à jour les modèles avec de nouvelles données pour maintenir leur précision et leur pertinence.\n",
    "    **Analyses Avancées** :\n",
    "Explorer des techniques avancées telles que l'analyse des séries temporelles et l'apprentissage profond pour améliorer les capacités prédictives.\n",
    "    **Qualité des Données** :\n",
    "Améliorer la qualité des données en traitant les valeurs manquantes, les valeurs aberrantes et les incohérences pour affiner les performances des modèles.\n",
    "## Travaux Futurs ##\n",
    "    **Analyse Temporelle** :\n",
    "Intégrer une analyse des séries temporelles pour comprendre les tendances et la saisonnalité dans les performances financières.\n",
    "Intégration de Données Externes :\n",
    "Incorporer des indicateurs économiques externes (par exemple, croissance du PIB, taux d'intérêt) pour enrichir l'ensemble de données et améliorer la précision des modèles.\n",
    "    **Rapports Automatisés**  :\n",
    "Développer des outils de rapports automatisés pour visualiser les principaux insights et faciliter la prise de décision.\n",
    "    **Surveillance en Temps Réel** :\n",
    "Implémenter des systèmes de surveillance en temps réel pour suivre les métriques financières clés et détecter rapidement les anomalies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
